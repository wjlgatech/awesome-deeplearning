# awesome-deeplearning

## Objectives
I aim to make everything here **TRUE**:
- **E**xecutable with code, **E**xpandable within a graph
- **U**nderstandable with *just enough* context and examples
- **R**eusable and **R**eproducible with simple & clear API (e.g. in the form of Python function, class, package)
- **T**ransferable and **T**ransformable to another domain and dimension, using best practices in graph ML and  ADEPT thinking= Analogy+Diagram+Example+PlainStorytelling+TechnicalAbstraction

### Also Checkout
- [Awesome-deeplearning](https://github.com/wjlgatech/awesome-deeplearning)
- [Awesome-Software-Engineering](https://github.com/wjlgatech/awesome-software-engineering)
- [Awesome-ReinforcementLearning](https://github.com/wjlgatech/awesome-reinforcementLearning)
- [Awesome-SQL](https://github.com/wjlgatech/awesome-sql)
- [Aweseome-Interview](https://github.com/wjlgatech/awesome-interview)

## Priority reading
- [/5] [Towards Learning Universal Hyperparameter Optimizers with Transformers](https://deepai.org/publication/towards-learning-universal-hyperparameter-optimizers-with-transformers)
- [/5] [A visual intro to deep learning](https://kdimensions.gumroad.com/l/visualdl)
- [/5] [The principle of deep learning: an effective theory approach to understanding neural network](https://arxiv.org/abs/2106.10165) 
- [/5] [Theory of Deep Learning](https://www.cs.princeton.edu/courses/archive/fall19/cos597B/lecnotes/bookdraft.pdf) Princeton Lectures
- [/5] [Alpa: automated model parallel deep learning](https://ai.googleblog.com/2022/05/alpa-automated-model-parallel-deep.html)
- [/5] [Richard Xu: ML learning theory](https://github.com/roboticcam/machine-learning-notes)


### Transformer
- [transformer intro: all you need to know to be dangeous](https://aman.ai/primers/ai/transformers/)

### MultimodalML
- [/5] [Multimodel: One model to learn them all](https://arxiv.org/abs/1706.05137)
- [/5] To improve mutimodal-ml signal mix [google AI align image with text with Contrastive Captioner (coca)](https://www.marktechpost.com/2022/05/30/google-ai-proposes-contrastive-captioner-coca-a-novel-encoder-decoder-model-that-simultaneously-produces-aligned-unimodal-image-and-text-embeddings/)

### CausalML & GraphML
- [/5] [Towards Causal Representation Learning](https://arxiv.org/abs/2102.11107)
- [/5] [How does the brain learn mental models? Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps](https://lnkd.in/ep4kKCXu)
- [/5][Learning to simulate complex physics with graph networks](https://arxiv.org/abs/2002.09405)

### big or stange ideas
- [How special relativity can help AI predict the future](https://www.technologyreview.com/2020/08/28/1007770/special-relativity-light-cones-ai-predict-future-causality-medicine/?utm_campaign=site_visitor.unpaid.engagement&utm_source=LinkedIn&utm_medium=tr_social)

- [What are the most important stat ideas in the past 50 years?](http://www.stat.columbia.edu/~gelman/research/unpublished/stat50.pdf)

## github
- [Trax](https://github.com/google/trax) by Google, an End to End library for deep learning with clean code & speed.



